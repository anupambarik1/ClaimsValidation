# ğŸ“‹ NLP Integration - Detailed Rationale & QA Guide

**File-by-File, Method-by-Method Explanation with Sequential Flow**

---

## Table of Contents
1. [Architecture Overview](#architecture-overview)
2. [Component Breakdown](#component-breakdown)
3. [Sequential Flow Explanation](#sequential-flow-explanation)
4. [File-by-File Analysis](#file-by-file-analysis)
5. [Method-by-Method Details](#method-by-method-details)
6. [QA Testing Guide](#qa-testing-guide)
7. [Data Transformation Walkthrough](#data-transformation-walkthrough)

---

## Architecture Overview

### Why NLP Integration?

**Problem**: Traditional ML models for fraud detection rely only on structured claim features (amount, policy type, etc.).

**Solution**: Add AI-powered NLP analysis to examine the **narrative content** of claims:
- Read claim description/OCR text
- Analyze writing patterns for fraud indicators
- Extract key entities (names, dates, amounts)
- Combine with ML scoring for better accuracy

**Result**: **60% ML + 40% NLP = Better fraud detection**

---

## Component Breakdown

### High-Level Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Layer (Claims.Api)                               â”‚
â”‚  â€¢ Controllers/ClaimsController.cs                     â”‚
â”‚  â€¢ appsettings.json (Configuration)                    â”‚
â”‚  â€¢ Program.cs (Dependency Injection)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Service Layer (Claims.Services)                       â”‚
â”‚  â”œâ”€ ClaimsService (Orchestration)                      â”‚
â”‚  â”œâ”€ AWSNlpService (NLP Processing) â­ NEW             â”‚
â”‚  â””â”€ AWSBedrockService (Claude 3 API) â­ NEW           â”‚
â”‚                                                         â”‚
â”‚  Supporting Services:                                  â”‚
â”‚  â”œâ”€ DocumentAnalysisService (OCR)                      â”‚
â”‚  â”œâ”€ RulesEngineService (Business Rules)                â”‚
â”‚  â”œâ”€ MlScoringService (Traditional ML)                  â”‚
â”‚  â””â”€ [Other services]                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Domain Layer (Claims.Domain)                          â”‚
â”‚  â€¢ DTOs/ClaimProcessingResult.cs (Response)            â”‚
â”‚  â€¢ Entities/Claim.cs (Data Model)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  External Services                                      â”‚
â”‚  â€¢ AWS Bedrock (Claude 3 Haiku) - AI Analysis         â”‚
â”‚  â€¢ AWS Comprehend - Sentiment & Entities              â”‚
â”‚  â€¢ AWS S3 - Document Storage                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Sequential Flow Explanation

### User Submits Claim: End-to-End Flow

```
STEP 0: USER INPUT
â””â”€ HTTP POST /api/claims/submit-and-process
   {
     "policyId": "POL-2024-567890",
     "claimantId": "CLMT-JOHN-DAVIS",
     "totalAmount": 8850.00,
     "documents": [
       {
         "documentType": 0,
         "fileName": "claim.pdf",
         "base64Content": "JVBERi0xLjQK..."  â† Encoded PDF content
       }
     ]
   }

STEP 1: API RECEIVES REQUEST
â””â”€ File: Claims.Api/Controllers/ClaimsController.cs
   Method: ProcessClaimAsync(...)
   Purpose: Validate HTTP request, deserialize JSON
   Action: Pass to ClaimsService

STEP 2: ORCHESTRATION BEGINS
â””â”€ File: Claims.Services/Implementations/ClaimsService.cs
   Method: ProcessClaimAsync(claim)
   Purpose: Orchestrate entire claim processing pipeline
   Action: Call sub-services in sequence

STEP 2.1: OCR EXTRACTION
â””â”€ File: Claims.Services/Implementations/DocumentAnalysisService.cs
   Method: ExtractTextAsync(documentPath)
   Purpose: Read document, extract text via OCR
   Input: Document file path or content
   Output: extractedText (string)
   Example Output: "CLAIM INFORMATION\nClaim Number: CLM-2024-001234..."

STEP 2.2: BUSINESS RULES VALIDATION
â””â”€ File: Claims.Services/Implementations/RulesEngineService.cs
   Method: ValidateAsync(claim)
   Purpose: Check policy limits, validity, coverage
   Input: Claim entity
   Output: isValid (boolean), ruleResults (object)
   Example: Verifies claim amount < policy limit

STEP 2.3: â­ NLP ANALYSIS (NEW!)
â””â”€ File: Claims.Services/Aws/AWSNlpService.cs
   Purpose: AI-powered claim analysis using Bedrock + Comprehend
   
   â”œâ”€ Method 1: SummarizeClaimAsync(claimAmount, ocrText)
   â”‚  Purpose: Generate concise 2-3 sentence summary
   â”‚  Input: "$8850.00" + full OCR extracted text
   â”‚  Process:
   â”‚    1. Create prompt: "Summarize this claim in 2-3 sentences..."
   â”‚    2. Send prompt to AWSBedrockService
   â”‚    3. Claude 3 Haiku processes and responds
   â”‚  Output: "Auto accident claim for John Davis..."
   â”‚  Why: Provides human-readable summary for review
   â”‚
   â”œâ”€ Method 2: AnalyzeFraudNarrativeAsync(summary)
   â”‚  Purpose: Calculate fraud risk from claim narrative
   â”‚  Input: Summary from Method 1
   â”‚  Process:
   â”‚    1. Create fraud analysis prompt: "Is this claim fraudulent? Score 0-1..."
   â”‚    2. Send to AWSBedrockService â†’ Claude 3 analyzes
   â”‚       Output: { "riskScore": 0.28, "reasoning": "..." }
   â”‚    3. Send summary to AmazonComprehendClient â†’ DetectSentimentAsync()
   â”‚       Output: sentiment (POSITIVE/NEGATIVE/NEUTRAL), confidence scores
   â”‚    4. Apply sentiment bonus:
   â”‚       if (sentiment == NEGATIVE) fraudScore += 0.15
   â”‚    5. Clamp to range [0.0, 1.0]
   â”‚  Output: fraudRiskScore (0.28 in this example)
   â”‚  Why: AI detects fraud patterns humans might miss
   â”‚
   â”œâ”€ Method 3: ExtractEntitiesAsync(ocrText)
   â”‚  Purpose: Extract key information (names, dates, amounts, locations)
   â”‚  Input: Full OCR text from Step 2.1
   â”‚  Process:
   â”‚    1. Call AmazonComprehendClient.DetectEntitiesAsync()
   â”‚       Comprehend identifies: PERSON, DATE, LOCATION, QUANTITY
   â”‚       Output: [
   â”‚         { "type": "PERSON", "text": "John Michael Davis" },
   â”‚         { "type": "DATE", "text": "January 15, 2024" },
   â”‚         { "type": "LOCATION", "text": "Springfield, IL" },
   â”‚         { "type": "QUANTITY", "text": "$8,850" }
   â”‚       ]
   â”‚    2. Call AWSBedrockService to classify claim type
   â”‚       Prompt: "What type of claim? auto/medical/property/life?"
   â”‚       Output: { "claimType": "auto" }
   â”‚    3. Combine into JSON response
   â”‚  Output: { "names": [...], "dates": [...], "amounts": [...], "claimType": "auto" }
   â”‚  Why: Structured data for audit trail and system processing
   â”‚
   â””â”€ Method 4: GenerateClaimResponseAsync(summary)
      Purpose: Generate professional response letter (optional)
      Input: Claim summary
      Output: HTML formatted response template
      Why: Template for claim decision communication

STEP 2.4: TRADITIONAL ML SCORING
â””â”€ File: Claims.Services/Implementations/MlScoringService.cs
   Method: ScoreClaimAsync(claim)
   Purpose: Traditional machine learning fraud scoring
   Input: Claim features (amount, type, policy history)
   Process: ML model analyzes structured features
   Output: fraudScore_ML = 0.45 (example)
   Why: Baseline fraud detection from existing model

STEP 2.5: â­ FRAUD SCORE COMBINATION (NEW!)
â””â”€ File: Claims.Services/Implementations/ClaimsService.cs
   Method: ProcessClaimAsync(...) [continuation]
   Purpose: Merge ML and NLP scores using weighted formula
   
   Input:
   â”œâ”€ fraudScore_ML = 0.45 (from Step 2.4)
   â””â”€ fraudScore_NLP = 0.28 (from Step 2.3, Method 2)
   
   Formula:
   combinedFraudScore = (fraudScore_ML Ã— 0.60) + (fraudScore_NLP Ã— 0.40)
                      = (0.45 Ã— 0.60) + (0.28 Ã— 0.40)
                      = 0.27 + 0.112
                      = 0.382 (â‰ˆ 0.38)
   
   Rationale for 60/40 split:
   â€¢ ML (60%): More mature, proven track record
   â€¢ NLP (40%): New capability, complement ML weaknesses
   â€¢ Clamped to range [0.0, 1.0] for validity
   
   Output: combinedFraudScore = 0.38

STEP 2.6: FINAL DECISION
â””â”€ File: Claims.Services/Implementations/ClaimsService.cs
   Method: ProcessClaimAsync(...) [continuation]
   Purpose: Route claim to AutoApprove, Reject, or ManualReview
   
   Decision Logic:
   â”œâ”€ if (fraudScore < 0.30 && approvalScore > 0.80)
   â”‚  â””â”€ Decision: "AutoApprove"
   â”‚     Reason: Low risk, high approval confidence
   â”‚
   â”œâ”€ else if (fraudScore > 0.70)
   â”‚  â””â”€ Decision: "Reject"
   â”‚     Reason: High fraud risk, denial recommended
   â”‚
   â””â”€ else
      â””â”€ Decision: "ManualReview"
         Reason: Moderate risk, requires human review

STEP 3: BUILD RESPONSE
â””â”€ File: Claims.Domain/DTOs/ClaimProcessingResult.cs
   Purpose: Package all results into JSON response object
   
   Response Structure:
   {
     "claimId": "550e8400-...",           â† Unique identifier
     "success": true,                     â† Processing successful
     "finalDecision": "ManualReview",     â† Decision made
     "decisionReason": "Moderate risk...", â† Explanation
     
     "ocrResults": [                      â† From Step 2.1
       {
         "documentType": "AccidentReport",
         "extractedText": "CLAIM INFORMATION...",
         "confidence": 0.95
       }
     ],
     
     "rulesValidation": {                 â† From Step 2.2
       "isValid": true,
       "rulesChecked": ["PolicyLimit", "PolicyValidity"]
     },
     
     "nlpAnalysis": {                     â† From Step 2.3 â­ NEW
       "summary": "Auto accident claim...",
       "fraudRiskScore": 0.28,
       "detectedEntities": "{...}",
       "claimType": "auto"
     },
     
     "mlScoring": {                       â† From Step 2.4 & 2.5
       "fraudScore": 0.38,                â† Combined score!
       "approvalScore": 0.65,
       "fraudRiskLevel": "Low"
     },
     
     "processingTimeMs": 2847.5           â† Performance metric
   }

STEP 4: RETURN TO CLIENT
â””â”€ HTTP 200 OK Response
   Send JSON response with all results
```

---

## File-by-File Analysis

### 1. AWSBedrockService.cs (NEW)

**Location**: `src/Claims.Services/Aws/AWSBedrockService.cs`

**Purpose**: Wrapper around AWS Bedrock API for Claude 3 model

**Why Created**:
- Centralized Bedrock integration
- Reusable across all NLP services
- Easy to mock for testing
- Clean separation of concerns

**Constructor**:
```
AWSBedrockService(IConfiguration, ILogger)
â”œâ”€ Reads config from appsettings.json
â”‚  â”œâ”€ AWS:AccessKey
â”‚  â”œâ”€ AWS:SecretKey
â”‚  â”œâ”€ AWS:Region
â”‚  â”œâ”€ AWS:Bedrock:Model
â”‚  â”œâ”€ AWS:Bedrock:MaxTokens
â”‚  â””â”€ AWS:Bedrock:Temperature
â”œâ”€ Creates AWS credentials
â”œâ”€ Initializes AmazonBedrockRuntimeClient
â””â”€ Stores model parameters for reuse
```

**Key Method**: `InvokeClaudeAsync(string prompt)`

```
What it does:
1. Takes user prompt (e.g., "Summarize this claim...")
2. Wraps prompt in JSON message format:
   {
     "anthropic_version": "bedrock-2023-06-01",
     "max_tokens": 1024,
     "temperature": 0.7,
     "messages": [
       {
         "role": "user",
         "content": "YOUR PROMPT HERE"
       }
     ]
   }
3. Sends to AWS Bedrock Runtime API
4. Receives response JSON:
   {
     "content": [
       {
         "type": "text",
         "text": "Claude 3's response here..."
       }
     ]
   }
5. Extracts text from response
6. Returns string to caller

Error Handling:
- Logs errors with context
- Re-throws for caller to handle
- Allows graceful fallback
```

**QA Testing for AWSBedrockService**:
- âœ… Verify AWS credentials in appsettings.json are valid
- âœ… Verify API calls to Bedrock succeed (check CloudWatch logs)
- âœ… Verify responses are properly parsed
- âœ… Verify errors are logged with detail

---

### 2. AWSNlpService.cs (MODIFIED - Complete Rewrite)

**Location**: `src/Claims.Services/Aws/AWSNlpService.cs`

**Purpose**: Implements INlpService interface with Bedrock + Comprehend integration

**Why Rewritten**:
- Previous version was placeholder/incomplete
- Now provides complete NLP pipeline
- Uses Bedrock for AI analysis
- Uses Comprehend for NLP operations

**Implementation of INlpService**:

```csharp
public interface INlpService
{
    Task<string> SummarizeClaimAsync(string claimAmount, string ocrText);
    Task<string> AnalyzeFraudNarrativeAsync(string claimSummary);
    Task<string> ExtractEntitiesAsync(string ocrText);
    Task<string> GenerateClaimResponseAsync(string claimSummary);
}
```

**Method 1: SummarizeClaimAsync(claimAmount, ocrText)**

```
Input:
â”œâ”€ claimAmount: "8850.00"
â””â”€ ocrText: Full text from OCR extraction

Process:
1. Build prompt:
   "Summarize this insurance claim in 2-3 sentences. 
    Claim Amount: $8850.00
    Claim Details: [OCR TEXT HERE]"

2. Call AWSBedrockService.InvokeClaudeAsync(prompt)
   â””â”€ Claude 3 Haiku processes prompt
   â””â”€ Returns concise summary

3. Log result for audit trail

Output:
"Auto accident claim for John Davis. Vehicle collision at 
Main and Oak intersection on Jan 15, 2024. Total damages 
$8,850 after deductible. Two witnesses present."

Why:
- Provides quick overview without reading full document
- Used as input for fraud analysis
- Human-readable for review
```

**Method 2: AnalyzeFraudNarrativeAsync(claimSummary)**

```
Input:
â””â”€ claimSummary: Output from Method 1 (2-3 sentences)

Process (Two-Step):

Step A: Bedrock Fraud Analysis
â”œâ”€ Build prompt:
â”‚  "Analyze this claim summary for fraud indicators.
â”‚   Rate fraud risk as decimal 0.0 (safe) to 1.0 (fraud).
â”‚   Return JSON: { \"riskScore\": X.XX, \"reasoning\": \"...\" }
â”‚   Summary: [CLAIM SUMMARY HERE]"
â”‚
â”œâ”€ Call AWSBedrockService.InvokeClaudeAsync(prompt)
â”‚  â””â”€ Claude 3 analyzes narrative patterns
â”‚  â””â”€ Returns: { "riskScore": 0.28, "reasoning": "..." }
â”‚
â””â”€ Parse JSON response
   â””â”€ fraudRiskScore_bedrock = 0.28

Step B: Comprehend Sentiment Analysis
â”œâ”€ Call AmazonComprehendClient.DetectSentimentAsync(summary)
â”‚  â””â”€ Comprehend analyzes emotional tone
â”‚  â””â”€ Returns: { 
â”‚       "sentiment": "NEUTRAL",
â”‚       "sentimentScore": { 
â”‚         "positive": 0.1, 
â”‚         "negative": 0.05, 
â”‚         "neutral": 0.85 
â”‚       }
â”‚     }
â”‚
â””â”€ Apply fraud bonus:
   if (sentiment == "NEGATIVE")
     fraudRiskScore += 0.15  â† Negative language suspicious
   else if (sentiment == "POSITIVE")
     fraudRiskScore -= 0.05  â† Positive language less suspicious

Step C: Clamp to valid range
â””â”€ fraudRiskScore = Math.Max(0.0, Math.Min(fraudRiskScore, 1.0))

Output:
{ 
  "riskScore": 0.28,
  "sentiment": "NEUTRAL",
  "reasoning": "Claim narrative is consistent..."
}

Why:
- Bedrock detects fraud patterns (contradictions, exaggeration)
- Sentiment analysis detects emotional red flags
- Combined approach more accurate than either alone
```

**Method 3: ExtractEntitiesAsync(ocrText)**

```
Input:
â””â”€ ocrText: Full OCR text from document

Process (Two-Step):

Step A: Comprehend Entity Detection
â”œâ”€ Call AmazonComprehendClient.DetectEntitiesAsync(ocrText)
â”‚  â””â”€ Comprehend identifies named entities
â”‚  â””â”€ Returns: [
â”‚       { "type": "PERSON", "text": "John Michael Davis", "score": 0.98 },
â”‚       { "type": "DATE", "text": "January 15, 2024", "score": 0.99 },
â”‚       { "type": "LOCATION", "text": "Springfield, IL", "score": 0.95 },
â”‚       { "type": "QUANTITY", "text": "$8,850", "score": 0.97 }
â”‚     ]
â”‚
â””â”€ Group entities by type:
   â””â”€ names: ["John Michael Davis", "Robert James Thompson"]
   â””â”€ dates: ["January 15, 2024", "January 20, 2024"]
   â””â”€ locations: ["Springfield, IL"]
   â””â”€ amounts: [8850.00, 8500.00, 450.00]

Step B: Bedrock Claim Type Classification
â”œâ”€ Build prompt:
â”‚  "What type of insurance claim is this?
â”‚   Options: auto, medical, property, life, workers_comp
â”‚   Return: { \"claimType\": \"[type]\" }
â”‚   Document: [OCR TEXT]"
â”‚
â”œâ”€ Call AWSBedrockService.InvokeClaudeAsync(prompt)
â”‚  â””â”€ Claude 3 classifies based on content
â”‚  â””â”€ Returns: { "claimType": "auto" }
â”‚
â””â”€ Parse response

Step C: Combine Results
â””â”€ Return JSON: {
     "names": ["John Michael Davis", "Robert James Thompson"],
     "dates": ["January 15, 2024", "January 20, 2024"],
     "locations": ["Springfield, IL"],
     "amounts": [8850.00, 8500.00, 450.00],
     "claimType": "auto"
   }

Output Format:
JSON string with all entities organized by type

Why:
- Provides structured data for audit/compliance
- Verifies claim amounts are consistent
- Identifies all involved parties
- Classifies claim type automatically
- Used for fraud pattern detection
```

**Method 4: GenerateClaimResponseAsync(claimSummary)**

```
Input:
â””â”€ claimSummary: 2-3 sentence summary from Method 1

Process:
1. Build prompt:
   "Generate a professional insurance response letter 
    for this claim decision in HTML format.
    Claim Summary: [SUMMARY HERE]"

2. Call AWSBedrockService.InvokeClaudeAsync(prompt)
   â””â”€ Claude 3 generates response template

3. Return HTML string

Output:
"<html>
  <body>
    <h1>Claim Decision Letter</h1>
    <p>Dear Claimant...</p>
  </body>
</html>"

Why:
- Automates response letter generation
- Ensures consistent professional format
- Reduces manual work for claims team
```

**QA Testing for AWSNlpService**:
- âœ… Verify SummarizeClaimAsync returns 2-3 sentences
- âœ… Verify AnalyzeFraudNarrativeAsync returns valid fraud score (0.0-1.0)
- âœ… Verify ExtractEntitiesAsync identifies all names, dates, amounts
- âœ… Verify sentiment bonus is applied correctly
- âœ… Verify claim type classification is accurate
- âœ… Verify all JSON responses are valid and properly formatted

---

### 3. ClaimsService.cs (MODIFIED)

**Location**: `src/Claims.Services/Implementations/ClaimsService.cs`

**What Changed**: Added NLP integration into processing pipeline

**Constructor Change**:

```
Before:
public ClaimsService(
    IClaimsRepository claimsRepository,
    IDocumentAnalysisService documentAnalysisService,
    IRulesEngineService rulesEngineService,
    IMlScoringService mlScoringService,
    INotificationService notificationService)

After (ADDED):
public ClaimsService(
    IClaimsRepository claimsRepository,
    IDocumentAnalysisService documentAnalysisService,
    IRulesEngineService rulesEngineService,
    INlpService nlpService,                    â† NEW!
    IMlScoringService mlScoringService,
    INotificationService notificationService)

Injection:
private readonly INlpService _nlpService;     â† NEW!
```

**ProcessClaimAsync Method - Key Changes**:

```
// Step 2.1: OCR Processing (unchanged)
var ocrResults = await _documentAnalysisService.ExtractTextAsync(documentPath);
var ocrText = ocrResults.First().ExtractedText;

// Step 2.2: Rules Validation (unchanged)
var rulesResult = await _rulesEngineService.ValidateAsync(claim);

// NEW! Step 2.3: NLP Analysis
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Step 2.3a: Summarize Claim
var summary = await _nlpService.SummarizeClaimAsync(
    claim.TotalAmount.ToString(),
    ocrText);

// Step 2.3b: Analyze Fraud Narrative
var fraudNarrativeJson = await _nlpService.AnalyzeFraudNarrativeAsync(summary);
var narrativeFraudScore = (decimal)JsonDocument
    .Parse(fraudNarrativeJson)
    .RootElement
    .GetProperty("riskScore")
    .GetDouble();

// Step 2.3c: Extract Entities
var entitiesJson = await _nlpService.ExtractEntitiesAsync(ocrText);
var entities = JsonDocument.Parse(entitiesJson);
var claimType = entities.RootElement.GetProperty("claimType").GetString();

// Step 2.3d: Store NLP Results
result.NlpAnalysis = new NlpAnalysisResult
{
    Summary = summary,
    FraudRiskScore = narrativeFraudScore,
    DetectedEntities = entitiesJson,
    ClaimType = claimType
};
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Step 2.4: ML Scoring (unchanged)
decimal fraudScore_ML = await _mlScoringService.ScoreClaimAsync(claim);

// NEW! Step 2.5: Fraud Score Combination
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Before: claim.FraudScore = fraudScore_ML;
// After:
var combinedFraudScore = (fraudScore_ML * 0.6m) + (narrativeFraudScore * 0.4m);
combinedFraudScore = Math.Min(Math.Max(combinedFraudScore, 0.0m), 1.0m);
claim.FraudScore = combinedFraudScore;
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Step 2.6: Final Decision (updated to use combined score)
if (combinedFraudScore < 0.30m && approvalScore > 0.80m)
{
    claim.Status = "AutoApproved";
    result.FinalDecision = "AutoApprove";
}
else if (combinedFraudScore > 0.70m)
{
    claim.Status = "Rejected";
    result.FinalDecision = "Reject";
}
else
{
    claim.Status = "PendingManualReview";
    result.FinalDecision = "ManualReview";
}
```

**QA Testing for ClaimsService**:
- âœ… Verify NLP service is called (check logs for "Step 2.5" message)
- âœ… Verify combined fraud score is calculated correctly
- âœ… Verify formula: (ML Ã— 0.6) + (NLP Ã— 0.4)
- âœ… Verify fraud score is between 0.0-1.0
- âœ… Verify decision logic uses combined score
- âœ… Verify NlpAnalysis is populated in response
- âœ… Verify processing time includes NLP calls (~2-3 seconds longer)

---

### 4. Program.cs (MODIFIED)

**Location**: `src/Claims.Api/Program.cs`

**Purpose**: Dependency injection configuration

**Change**:

```csharp
// Added: NLP Service Registration
var useAwsBedrock = builder.Configuration.GetValue<bool>("AWS:Bedrock:Enabled");
var awsEnabled = builder.Configuration.GetValue<bool>("AWS:Enabled");

if (awsEnabled && useAwsBedrock)
{
    // Register Bedrock services (PREFERRED)
    builder.Services.AddSingleton<AWSBedrockService>();
    builder.Services.AddSingleton<INlpService, AWSNlpService>();
}
else
{
    // Fallback to default (if Bedrock disabled)
    builder.Services.AddSingleton<INlpService, DefaultNlpService>();
}
```

**Why**:
- Enables/disables NLP based on configuration
- Allows testing without AWS credentials
- Follows Dependency Injection pattern
- Allows swapping implementations

**QA Testing for Program.cs**:
- âœ… Verify AWSBedrockService is registered when AWS:Enabled=true
- âœ… Verify AWSNlpService is registered when Bedrock:Enabled=true
- âœ… Verify fallback works when AWS disabled
- âœ… Verify no exceptions during startup

---

### 5. appsettings.json (MODIFIED)

**Location**: `src/Claims.Api/appsettings.json`

**Added Section**:

```json
{
  "AWS": {
    "Enabled": true,
    "Region": "us-east-1",
    "AccessKey": "AKIA...",              â† Your AWS Access Key
    "SecretKey": "wJalr...",             â† Your AWS Secret Key
    "Bedrock": {
      "Enabled": true,
      "Model": "anthropic.claude-3-5-haiku-20241022-v1:0",
      "MaxTokens": 1024,
      "Temperature": 0.7
    }
  }
}
```

**Field Explanations**:

| Field | Value | Purpose |
|-------|-------|---------|
| Enabled | true/false | Turn AWS integration on/off |
| Region | us-east-1 | AWS region (must have Bedrock) |
| AccessKey | AKIA... | AWS IAM access key |
| SecretKey | wJalr... | AWS IAM secret key |
| Bedrock.Enabled | true/false | Turn Bedrock specifically on/off |
| Model | claude-3-5-haiku-20241022-v1:0 | Which Claude model to use |
| MaxTokens | 1024 | Max response length |
| Temperature | 0.7 | Creativity level (0.0=deterministic, 1.0=creative) |

**QA Testing for appsettings.json**:
- âœ… Verify AWS:Enabled is true
- âœ… Verify AWS credentials are valid (can auth to AWS)
- âœ… Verify Region is us-east-1 (has Bedrock)
- âœ… Verify Bedrock:Enabled is true
- âœ… Verify Model ID is correct
- âœ… Verify MaxTokens is reasonable (1024 is good)
- âœ… Verify Temperature is between 0.0 and 1.0

---

### 6. ClaimProcessingResult.cs (MODIFIED)

**Location**: `src/Claims.Domain/DTOs/ClaimProcessingResult.cs`

**Change**: Added NlpAnalysisResult class

```csharp
// NEW! Class
public class NlpAnalysisResult
{
    /// <summary>
    /// 2-3 sentence summary of the claim generated by Claude 3
    /// </summary>
    public string? Summary { get; set; }
    
    /// <summary>
    /// Fraud risk score from NLP analysis (0.0 = safe, 1.0 = fraud)
    /// </summary>
    public decimal FraudRiskScore { get; set; }
    
    /// <summary>
    /// JSON string containing detected entities:
    /// { "names": [...], "dates": [...], "locations": [...], "amounts": [...] }
    /// </summary>
    public string? DetectedEntities { get; set; }
    
    /// <summary>
    /// Claim type classification: auto, medical, property, life
    /// </summary>
    public string? ClaimType { get; set; }
}

// Updated ClaimProcessingResult
public class ClaimProcessingResult
{
    // ... existing properties ...
    
    /// <summary>
    /// NLP analysis results (NEW!)
    /// </summary>
    public NlpAnalysisResult? NlpAnalysis { get; set; }
}
```

**Example JSON Output**:

```json
{
  "nlpAnalysis": {
    "summary": "Auto accident claim for John Davis. Vehicle collision at Main and Oak intersection on Jan 15, 2024. Total damages $8,850 after deductible. Two witnesses present.",
    "fraudRiskScore": 0.28,
    "detectedEntities": "{\"names\":[\"John Michael Davis\",\"Robert James Thompson\"],\"dates\":[\"January 15, 2024\"],\"locations\":[\"Springfield, IL\"],\"amounts\":[8850.00]}",
    "claimType": "auto"
  }
}
```

**QA Testing for ClaimProcessingResult**:
- âœ… Verify nlpAnalysis is present in response
- âœ… Verify summary is not null and is readable
- âœ… Verify fraudRiskScore is decimal between 0.0-1.0
- âœ… Verify detectedEntities is valid JSON
- âœ… Verify claimType is one of valid values
- âœ… Verify JSON serialization works correctly

---

### 7. Claims.Services.csproj (MODIFIED)

**Location**: `src/Claims.Services/Claims.Services.csproj`

**Added Packages**:

```xml
<ItemGroup>
    <PackageReference Include="AWSSDK.Comprehend" Version="3.7.3" />
    <PackageReference Include="AWSSDK.BedrockRuntime" Version="3.7.200" />
</ItemGroup>
```

**Why Each Package**:

| Package | Version | Purpose | Used In |
|---------|---------|---------|---------|
| AWSSDK.BedrockRuntime | 3.7.200 | Invoke Claude 3 models | AWSBedrockService |
| AWSSDK.Comprehend | 3.7.3 | Entity extraction, sentiment | AWSNlpService |
| AWSSDK.Core | 3.7.100 | Base AWS SDK | All AWS services |

**QA Testing for Packages**:
- âœ… Verify packages restore successfully (`dotnet restore`)
- âœ… Verify no version conflicts
- âœ… Verify solution builds without errors
- âœ… Verify namespaces are available (Amazon.BedrockRuntime, Amazon.Comprehend)

---

## Method-by-Method Details

### Summary of All Methods

| File | Class | Method | Input | Output | Purpose |
|------|-------|--------|-------|--------|---------|
| AWSBedrockService.cs | AWSBedrockService | InvokeClaudeAsync | prompt | response text | Send prompt to Claude 3 |
| AWSNlpService.cs | AWSNlpService | SummarizeClaimAsync | amount, text | summary | Generate 2-3 sentence summary |
| AWSNlpService.cs | AWSNlpService | AnalyzeFraudNarrativeAsync | summary | fraud JSON | Calculate fraud risk from narrative |
| AWSNlpService.cs | AWSNlpService | ExtractEntitiesAsync | text | entities JSON | Extract names, dates, amounts |
| AWSNlpService.cs | AWSNlpService | GenerateClaimResponseAsync | summary | response HTML | Generate response letter |
| ClaimsService.cs | ClaimsService | ProcessClaimAsync | claimId | result object | Orchestrate entire pipeline |

---

## QA Testing Guide

### Test Scenario 1: Happy Path (Valid Claim)

**Test Case**: Submit legitimate auto accident claim

**Preconditions**:
- API is running
- AWS credentials are valid
- Bedrock is enabled in config
- Sample document exists

**Steps**:

1. **Start API**
   ```powershell
   cd src/Claims.Api
   dotnet run
   # Wait for: "Now listening on: http://localhost:5000"
   ```

2. **Submit Claim with Document**
   ```
   POST /api/claims/submit-and-process
   Body:
   {
     "policyId": "POL-2024-567890",
     "claimantId": "CLMT-JOHN-DAVIS",
     "totalAmount": 8850.00,
     "documents": [
       {
         "documentType": 0,
         "fileName": "claim.pdf",
         "base64Content": "JVBERi0xLjQK..."
       }
     ]
   }
   ```

3. **Verify Response**
   ```
   Check response includes:
   âœ… claimId (UUID)
   âœ… success = true
   âœ… nlpAnalysis object exists
   âœ… nlpAnalysis.summary is readable (2-3 sentences)
   âœ… nlpAnalysis.fraudRiskScore = 0.28 (between 0.0-1.0)
   âœ… nlpAnalysis.claimType = "auto"
   âœ… mlScoring.fraudScore = 0.38 (combined)
   âœ… finalDecision = "ManualReview"
   âœ… processingTimeMs â‰ˆ 2800-4000 ms (includes NLP calls)
   ```

4. **Check Logs**
   ```
   Verify API console output contains:
   âœ… "Starting AI processing for claim..."
   âœ… "Step 1: OCR Processing..."
   âœ… "Step 2: Business Rules Validation..."
   âœ… "Step 2.5: NLP Analysis"          â† KEY INDICATOR
   âœ… "Claim summarized successfully"
   âœ… "Fraud analysis completed..."
   âœ… "Entities extracted..."
   âœ… "Step 3: ML Fraud Detection..."
   âœ… "Claim scored: FraudScore=..."
   ```

5. **Verify NLP Components**
   ```
   In response.nlpAnalysis:
   
   âœ… Summary Check
      â€¢ 2-3 sentences
      â€¢ Mentions claimant name (John Davis)
      â€¢ Mentions incident type (auto accident)
      â€¢ Mentions date (Jan 15, 2024)
   
   âœ… Fraud Risk Score Check
      â€¢ Number between 0.0 and 1.0
      â€¢ For this claim: should be â‰¤ 0.4 (legitimate)
   
   âœ… Detected Entities Check
      â€¢ Contains JSON with names array
      â€¢ Contains dates array
      â€¢ Contains locations array
      â€¢ Contains amounts array
   
   âœ… Claim Type Check
      â€¢ Value = "auto"
      â€¢ Matches document content
   ```

6. **Verify Fraud Score Combination**
   ```
   Calculate expected combined score:
   
   If ML Score = 0.45 and NLP Score = 0.28
   Expected Combined = (0.45 Ã— 0.60) + (0.28 Ã— 0.40)
                     = 0.27 + 0.112
                     = 0.382
   
   âœ… Response.mlScoring.fraudScore should equal ~0.38
   ```

---

### Test Scenario 2: Error Handling

**Test Case**: Process claim with missing AWS credentials

**Steps**:

1. **Set AWS:Enabled = false** in appsettings.json
2. **Restart API**
3. **Submit claim**
4. **Verify**:
   - âœ… API returns error or falls back
   - âœ… NlpAnalysis is null/empty
   - âœ… Error is logged with detail
   - âœ… API doesn't crash

---

### Test Scenario 3: Performance

**Test Case**: Measure NLP processing time

**Expected Results**:
- Bedrock summarization: 300-600 ms
- Fraud analysis (Bedrock + Comprehend): 600-1000 ms
- Entity extraction: 300-500 ms
- **Total NLP time**: 1200-2100 ms
- **Total request time**: 3000-4500 ms (with DB/other operations)

**QA Validation**:
```
âœ… processingTimeMs < 5000
âœ… NLP contributes 1-2 seconds
âœ… Consistent across multiple runs
âœ… No timeout errors
```

---

### Test Scenario 4: Different Claim Types

**Test with Medical Claim**:

```json
{
  "policyId": "POL-MED-123456",
  "claimantId": "CLMT-JANE-DOE",
  "totalAmount": 5000.00,
  "documents": [{
    "documentType": 0,
    "fileName": "medical.pdf",
    "base64Content": "..."
  }]
}
```

**Expected**:
- âœ… NlpAnalysis.claimType = "medical"
- âœ… Summary mentions medical terms (diagnosis, treatment, etc.)
- âœ… FraudRiskScore reflects medical fraud patterns

---

### Test Scenario 5: Fraud Detection

**Test with Suspicious Claim**:

```json
{
  "policyId": "POL-2024-999999",
  "claimantId": "CLMT-SUSPICIOUS",
  "totalAmount": 50000.00,
  "documents": [{
    "documentType": 0,
    "fileName": "suspicious.pdf",
    "base64Content": "..."
  }]
}
```

**Expected**:
- âœ… nlpAnalysis.fraudRiskScore > 0.6
- âœ… mlScoring.fraudScore > 0.6
- âœ… finalDecision = "Reject"
- âœ… Summary should note suspicious indicators

---

## Data Transformation Walkthrough

### Complete Data Journey

```
STEP 1: USER SUBMITS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HTTP POST /api/claims/submit-and-processâ”‚
â”‚ {                                       â”‚
â”‚   "policyId": "POL-2024-567890",      â”‚
â”‚   "claimantId": "CLMT-JOHN-DAVIS",    â”‚
â”‚   "totalAmount": 8850.00,              â”‚
â”‚   "documents": [{                       â”‚
â”‚     "documentType": 0,                  â”‚
â”‚     "fileName": "claim.pdf",           â”‚
â”‚     "base64Content": "JVBERi0xLjQK..."â”‚
â”‚   }]                                    â”‚
â”‚ }                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
STEP 2: CONTROLLER RECEIVES
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ClaimsController.ProcessClaimAsync()   â”‚
â”‚                                         â”‚
â”‚ Deserializes JSON                       â”‚
â”‚ Validates input                         â”‚
â”‚ Decodes base64 to binary document       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
STEP 3: CREATE CLAIM ENTITY
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Claim Entity                            â”‚
â”‚ {                                       â”‚
â”‚   ClaimId: 550e8400-...,               â”‚
â”‚   PolicyId: "POL-2024-567890",         â”‚
â”‚   ClaimantId: "CLMT-JOHN-DAVIS",       â”‚
â”‚   TotalAmount: 8850.00,                â”‚
â”‚   Status: "Processing",                â”‚
â”‚   SubmittedDate: 2026-01-02T10:00:00  â”‚
â”‚ }                                       â”‚
â”‚                                         â”‚
â”‚ Saved to Database                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
STEP 4: EXTRACT OCR TEXT
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DocumentAnalysisService.ExtractTextAsyncâ”‚
â”‚                                         â”‚
â”‚ Input: Document binary (PDF)            â”‚
â”‚ Process: OCR extraction                 â”‚
â”‚ Output: Text string                     â”‚
â”‚                                         â”‚
â”‚ "CLAIM INFORMATION                      â”‚
â”‚  Claim Number: CLM-2024-001234          â”‚
â”‚  Date of Loss: January 15, 2024         â”‚
â”‚  Claim Type: Auto Accident              â”‚
â”‚  POLICYHOLDER INFORMATION               â”‚
â”‚  Name: John Michael Davis               â”‚
â”‚  Policy Number: POL-2024-567890         â”‚
â”‚  INCIDENT DETAILS                       â”‚
â”‚  Location: Main Street and Oak Avenue   â”‚
â”‚  ...                                    â”‚
â”‚  NET CLAIM REQUEST: $8,850.00           â”‚
â”‚ "                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
STEP 5: VALIDATE BUSINESS RULES
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RulesEngineService.ValidateAsync()     â”‚
â”‚                                         â”‚
â”‚ Checks:                                 â”‚
â”‚ â€¢ PolicyLimit: 8850 < 100000 âœ“          â”‚
â”‚ â€¢ PolicyValidity: Not expired âœ“         â”‚
â”‚ â€¢ CoverageCheck: Auto covered âœ“         â”‚
â”‚                                         â”‚
â”‚ Output: { isValid: true }               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
STEP 6: â­ NLP ANALYSIS BEGINS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AWSNlpService.SummarizeClaimAsync()    â”‚
â”‚                                         â”‚
â”‚ Input:                                  â”‚
â”‚  â€¢ claimAmount: "8850.00"              â”‚
â”‚  â€¢ ocrText: Full 126-line document     â”‚
â”‚                                         â”‚
â”‚ Prompt:                                 â”‚
â”‚  "Summarize this claim in 2-3 sentencesâ”‚
â”‚   Claim Amount: $8850.00                â”‚
â”‚   Details: [OCR TEXT]"                 â”‚
â”‚                                         â”‚
â”‚ Calls: AWSBedrockService.InvokeClaudeAsyncâ”‚
â”‚   â†’ AWS Bedrock API                     â”‚
â”‚   â†’ Claude 3 Haiku Model               â”‚
â”‚                                         â”‚
â”‚ Output:                                 â”‚
â”‚  "Auto accident claim for John Davis... â”‚
â”‚   Vehicle collision Jan 15, 2024...     â”‚
â”‚   Two witnesses present."               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
STEP 7: FRAUD NARRATIVE ANALYSIS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AWSNlpService.AnalyzeFraudNarrativeAsyncâ”‚
â”‚                                         â”‚
â”‚ Input: Summary from Step 6              â”‚
â”‚                                         â”‚
â”‚ Part A: Bedrock Fraud Analysis          â”‚
â”‚  Prompt: "Rate fraud risk 0.0-1.0..."  â”‚
â”‚  Response: { "riskScore": 0.28 }       â”‚
â”‚                                         â”‚
â”‚ Part B: Comprehend Sentiment Analysis   â”‚
â”‚  Input: Summary text                    â”‚
â”‚  Response: { "sentiment": "NEUTRAL" }   â”‚
â”‚  No bonus applied (neutral = normal)    â”‚
â”‚                                         â”‚
â”‚ Output: fraudRiskScore = 0.28           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
STEP 8: ENTITY EXTRACTION
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AWSNlpService.ExtractEntitiesAsync()   â”‚
â”‚                                         â”‚
â”‚ Part A: Comprehend Entity Detection     â”‚
â”‚  Input: Full OCR text                   â”‚
â”‚  Extracts: Names, Dates, Locations     â”‚
â”‚  Output: [                              â”‚
â”‚    {PERSON: "John Michael Davis"},      â”‚
â”‚    {PERSON: "Robert James Thompson"},   â”‚
â”‚    {DATE: "January 15, 2024"},          â”‚
â”‚    {LOCATION: "Springfield, IL"},       â”‚
â”‚    {QUANTITY: "$8,850"}                 â”‚
â”‚  ]                                      â”‚
â”‚                                         â”‚
â”‚ Part B: Bedrock Claim Classification    â”‚
â”‚  Prompt: "What claim type?"             â”‚
â”‚  Response: { "claimType": "auto" }      â”‚
â”‚                                         â”‚
â”‚ Output: JSON with all entities          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
STEP 9: TRADITIONAL ML SCORING
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MlScoringService.ScoreClaimAsync()     â”‚
â”‚                                         â”‚
â”‚ Input: Claim features                   â”‚
â”‚  â€¢ Amount: 8850 (medium)                â”‚
â”‚  â€¢ Type: Auto (common)                  â”‚
â”‚  â€¢ History: Clean (good)                â”‚
â”‚                                         â”‚
â”‚ ML Model Analysis                       â”‚
â”‚  Fraud Pattern Detection                â”‚
â”‚  Feature Engineering                    â”‚
â”‚                                         â”‚
â”‚ Output:                                 â”‚
â”‚  â€¢ fraudScore_ML: 0.45                  â”‚
â”‚  â€¢ approvalScore: 0.65                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
STEP 10: â­ FRAUD SCORE COMBINATION
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ClaimsService.ProcessClaimAsync()      â”‚
â”‚                                         â”‚
â”‚ Formula:                                â”‚
â”‚  combined = (ML Ã— 0.60) + (NLP Ã— 0.40) â”‚
â”‚  combined = (0.45 Ã— 0.60) + (0.28 Ã— 0.40)â”‚
â”‚  combined = 0.27 + 0.112               â”‚
â”‚  combined = 0.382 â‰ˆ 0.38               â”‚
â”‚                                         â”‚
â”‚ Stored in: Claim.FraudScore = 0.38      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
STEP 11: FINAL DECISION
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Decision Logic                          â”‚
â”‚                                         â”‚
â”‚ if (fraudScore < 0.30 && approval > 0.80)â”‚
â”‚   â†’ "AutoApprove" âŒ (fraud=0.38)      â”‚
â”‚                                         â”‚
â”‚ else if (fraudScore > 0.70)             â”‚
â”‚   â†’ "Reject" âŒ (fraud=0.38)           â”‚
â”‚                                         â”‚
â”‚ else                                    â”‚
â”‚   â†’ "ManualReview" âœ… (fraud=0.38)     â”‚
â”‚                                         â”‚
â”‚ Status: PendingManualReview             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
STEP 12: BUILD RESPONSE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ClaimProcessingResult                   â”‚
â”‚ {                                       â”‚
â”‚   claimId: "550e8400-...",             â”‚
â”‚   success: true,                        â”‚
â”‚   finalDecision: "ManualReview",       â”‚
â”‚   decisionReason: "Moderate risk...",   â”‚
â”‚                                         â”‚
â”‚   ocrResults: [                         â”‚
â”‚     {                                   â”‚
â”‚       documentType: "AccidentReport",   â”‚
â”‚       extractedText: "CLAIM INFO...",  â”‚
â”‚       confidence: 0.95                  â”‚
â”‚     }                                   â”‚
â”‚   ],                                    â”‚
â”‚                                         â”‚
â”‚   rulesValidation: {                    â”‚
â”‚     isValid: true,                      â”‚
â”‚     ruleResults: [...]                  â”‚
â”‚   },                                    â”‚
â”‚                                         â”‚
â”‚   nlpAnalysis: { â­ NEW!               â”‚
â”‚     summary: "Auto accident claim...",  â”‚
â”‚     fraudRiskScore: 0.28,              â”‚
â”‚     detectedEntities: "{...}",         â”‚
â”‚     claimType: "auto"                   â”‚
â”‚   },                                    â”‚
â”‚                                         â”‚
â”‚   mlScoring: {                          â”‚
â”‚     fraudScore: 0.38,    â† COMBINED!   â”‚
â”‚     approvalScore: 0.65,               â”‚
â”‚     fraudRiskLevel: "Low"               â”‚
â”‚   },                                    â”‚
â”‚                                         â”‚
â”‚   processingTimeMs: 2847.5              â”‚
â”‚ }                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
STEP 13: RETURN RESPONSE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HTTP 200 OK                             â”‚
â”‚ Content-Type: application/json          â”‚
â”‚ Body: ClaimProcessingResult JSON        â”‚
â”‚                                         â”‚
â”‚ Client receives complete results       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## QA Checklist

### Pre-Testing Checklist

- [ ] Clone latest code
- [ ] Build solution: `dotnet build`
- [ ] Verify no compilation errors
- [ ] Check AWS credentials in appsettings.json
- [ ] Verify AWS:Bedrock:Enabled = true
- [ ] Verify AWS region = us-east-1
- [ ] Verify sample document exists

### During Testing Checklist

- [ ] API starts without errors
- [ ] Bedrock service initializes
- [ ] Comprehend client initializes
- [ ] First request succeeds
- [ ] NLP analysis completes
- [ ] Fraud scores are calculated
- [ ] Decision is made

### Post-Testing Checklist

- [ ] Response includes nlpAnalysis
- [ ] Summary is readable
- [ ] fraudRiskScore is 0.0-1.0
- [ ] Entities are extracted correctly
- [ ] Claim type is classified
- [ ] Combined fraud score is correct
- [ ] Final decision is appropriate
- [ ] Processing time is logged
- [ ] No errors in API logs
- [ ] No errors in AWS CloudWatch

---

## Conclusion

This implementation adds **AI-powered fraud detection** to the Claims Validation System by:

1. **Integrating AWS Bedrock** (Claude 3 Haiku) for narrative analysis
2. **Integrating AWS Comprehend** for entity extraction and sentiment
3. **Combining ML + NLP scores** with 60/40 weighting
4. **Maintaining backward compatibility** with fallback options
5. **Providing complete audit trail** with detailed logging

**Key Achievement**: System now analyzes both **structured data (ML)** and **narrative content (NLP)** for more accurate fraud detection.

